{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General understanding about the example data\n",
    "Lets first have a look at the data. From the example file, we  \n",
    "can see that the data is structured like this. Chargerstations  \n",
    "contains all the `chargingstations` that were found in the search.  \n",
    "\n",
    "For each charger station there are to types of information.  \n",
    "In `csmd` there is metadata on the charginstation such as the location,  \n",
    "country, ID of the charger and the number of connectors it has.  \n",
    "\n",
    "In `attr` there is some metadata that applies to all connectors in `st`  \n",
    "such as if it gives realtime data, or if it is publicly available.  \n",
    "There is also metadata on every connector that the charger has in `conn`.  \n",
    "Such as if it is available, if it is a public connector, if it has a  \n",
    "fixed cable or not.\n",
    "\n",
    "The goal is to first define what data we want from every connector  \n",
    "(conn) and every charging station (cs) and then create a common  \n",
    "database with all of this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(path):\n",
    "    with open(path) as json_data:\n",
    "        return js.load(json_data)\n",
    "    \n",
    "path = 'nobil_json/json_9.json'\n",
    "jsonFile = open_json(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the variables in CSMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csmd\n",
      "attr\n"
     ]
    }
   ],
   "source": [
    "for key in jsonFile['chargerstations'][1].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SWE'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonFile['chargerstations'][1]['csmd']['Land_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "name\n",
      "ocpidb_mapping_stasjon_id\n",
      "Street\n",
      "House_number\n",
      "Zipcode\n",
      "City\n",
      "Municipality_ID\n",
      "Municipality\n",
      "County_ID\n",
      "County\n",
      "Description_of_location\n",
      "Owned_by\n",
      "Operator\n",
      "Number_charging_points\n",
      "Position\n",
      "Image\n",
      "Available_charging_points\n",
      "User_comment\n",
      "Contact_info\n",
      "Created\n",
      "Updated\n",
      "Station_status\n",
      "Land_code\n",
      "International_id\n"
     ]
    }
   ],
   "source": [
    "for key in jsonFile['chargerstations'][1]['csmd'].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From looking at the keys, we can identify these as interesting for the following assignment.\n",
    "importantKeysCSMD = ['id','Owned_by','Operator','Number_charging_points','Position','Contact_info','Land_code','International_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the variables in ATTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['st', 'conn']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station = jsonFile['chargerstations'][2]\n",
    "attr = station['attr']\n",
    "list(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First look at the variables in ATTR / st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '3', '6', '7', '21', '22', '24']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(attr['st'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrtypeid': '2',\n",
       " 'attrname': 'Availability',\n",
       " 'attrvalid': '1',\n",
       " 'trans': 'Public',\n",
       " 'attrval': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr['st']['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Availability',\n",
       " 'Location',\n",
       " 'Time limit',\n",
       " 'Parking fee',\n",
       " 'Real-time information',\n",
       " 'Public funding',\n",
       " 'Open 24h']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_keys = list(attr['st'])\n",
    "\n",
    "st_attr_names = [attr['st'][key]['attrname'] for key in st_keys]\n",
    "\n",
    "st_attr_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First look at ATTR / conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keys of the connector\n",
    "list(attr['conn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these are a connector. Lets further deep dive into what keys they each have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '4', '5', '17', '18', '19', '20', '25', '26']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connector = attr['conn']['1']\n",
    "list(connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrtypeid': '1',\n",
       " 'attrname': 'Accessibility',\n",
       " 'attrvalid': '6',\n",
       " 'trans': 'Cellular phone',\n",
       " 'attrval': ''}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connector['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the ATTR / st we have the name of the attribute under attrname, and the value under trans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a function to decode and flatten a connector or st attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the stations\n",
    "def get_all_stations_from_dir(path):\n",
    "    allStations = []\n",
    "\n",
    "    if not '/' in path:\n",
    "        path += '/'\n",
    "\n",
    "    jsonPaths = [path+filename for filename in os.listdir(path)]\n",
    "    \n",
    "    for jsonPath in jsonPaths:\n",
    "        jsonFile = open_json(jsonPath)\n",
    "        stations = jsonFile['chargerstations']\n",
    "        allStations += stations\n",
    "\n",
    "    return allStations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stations all have `attr` as a branch. There is then both the `st` and the  \n",
    "`conn` key. While there are differences in how the st and connectors look once   \n",
    "you have put in the key i.e. `attr/conn` vs `attr/st`. They do have the same  \n",
    "syntax once you step into an individual connector. They each will have a key  \n",
    "which corresponds to the id of the attribute, and a value wich looks like this   \n",
    "\n",
    "{'attrtypeid': '1',  \n",
    " 'attrname': 'Accessibility',  \n",
    " 'attrvalid': '6',  \n",
    " 'trans': 'Cellular phone',  \n",
    " 'attrval': ''}  \n",
    "  \n",
    "Where you have two important key value pairs, `attrname` which is the name of  \n",
    "what the attribute describes and `trans` which is the value of the attribute.\n",
    "\n",
    "We will therefore need a function to turn each of these entries from what you  \n",
    "saw above into {`attrname`:`trans`}. For all of the existing attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_or_connector_to_dict(st_or_connector):\n",
    "    keys = list(st_or_connector)\n",
    "    attr_dict = {}\n",
    "\n",
    "    for key in keys:\n",
    "        attrname = st_or_connector[key]['attrname']\n",
    "        trans = st_or_connector[key]['trans']\n",
    "\n",
    "        attr_dict[attrname] = trans\n",
    "    \n",
    "    return attr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need a function that given a station can turn it into a  \n",
    "dictionary for every connector, containing both shared information which  \n",
    "is true for the station and information specific to the connector.\n",
    "\n",
    "At this point we can also chose not to keep some of the redundant categories  \n",
    "from the `CSMD` categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We chose only to keep the following categories from CSMD\n",
    "csmd_attr_names = ['id','Owned_by','Operator','Number_charging_points','Position','Contact_info','Land_code','International_id']\n",
    "\n",
    "def station_to_dictList(station,csmd_attr_names):\n",
    "    station_dict_list = []\n",
    "\n",
    "    csmd = station['csmd']\n",
    "    joint_dict = {key: csmd[key] for key in csmd_attr_names}\n",
    "\n",
    "    st = station['attr']['st']\n",
    "    st_dict = st_or_connector_to_dict(st)\n",
    "    joint_dict.update(st_dict)\n",
    "\n",
    "    connectors = station['attr']['conn']\n",
    "\n",
    "    for i, connector in enumerate(connectors.values()):\n",
    "        conn_dict = st_or_connector_to_dict(connector)\n",
    "        conn_dict['connectorNumber'] = i\n",
    "\n",
    "        temp_joint_dict = joint_dict.copy()\n",
    "        temp_joint_dict.update(conn_dict)\n",
    "\n",
    "        station_dict_list.append(temp_joint_dict)\n",
    "\n",
    "    return station_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a huge list of all of these dictionaries.\n",
    "def stations_list(stations):\n",
    "    list_of_dicts_all_stations = []\n",
    "    all_used_ids = []\n",
    "\n",
    "    for station in stations:\n",
    "        id = station['csmd']['International_id']\n",
    "\n",
    "        if not id in all_used_ids:\n",
    "\n",
    "            list_of_dicts_all_stations += station_to_dictList(station,csmd_attr_names)\n",
    "            all_used_ids.append(id)\n",
    "            \n",
    "    return list_of_dicts_all_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running all the functions and saving our dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = get_all_stations_from_dir('nobil_json')\n",
    "list_of_dicts_all_stations = stations_list(stations)\n",
    "df = pd.DataFrame(list_of_dicts_all_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the latitudes and longitudes separately as well\n",
    "def lat_lon_from_string(latLonString):\n",
    "    latLonString = str(latLonString)\n",
    "    latLonString = latLonString.strip('()')\n",
    "    latString,lonString = latLonString.split(',')\n",
    "    lat, lon = float(latString),float(lonString)\n",
    "    return lat,lon\n",
    "\n",
    "df['latlon'] = df['Position'].apply(lat_lon_from_string)\n",
    "df['lat'], df['lon'] = zip(*df['latlon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Land_code'] == \"SWE\"]\n",
    "df.to_csv('nobil_data_sweden.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
